{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0ecfa0",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Analysis\n",
    "### Raha Musavi-Masterarbeit-VAMoS\n",
    "This notebook provides a detailed analysis of the trained Logistic Regression model for identifying the presence of Ezafe in Middle Persian nominal phrases. It covers the evaluation metrics, ROC analysis, learning curve, data integrity checks, random label shuffling test, and error analysis, aligning with Sections 5.9 and 5.10 of the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61977a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup and Data Loading\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib # For loading the saved model\n",
    "from sklearn.model_selection import train_test_split, learning_curve, StratifiedKFold # learning_curve, StratifiedKFold for learning curve\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler # For reproducing the split\n",
    "from sklearn.utils import shuffle # For random label shuffling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os # To check if files exist\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d1c6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Required input files not found.\n",
      "Please ensure 'lr_final_features.csv', 'lr_target.csv', and 'final_logistic_regression_model.pkl' exist.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration --- (Matches lr_train_evaluate.py configuration for consistency)\n",
    "INPUT_FEATURES_CSV = \"lr_final_features.csv\"\n",
    "INPUT_TARGET_CSV = \"lr_target.csv\"\n",
    "INPUT_MODEL_PATH = \"final_logistic_regression_model.pkl\"\n",
    "\n",
    "# Configuration needed to reproduce the train/test split and resampling\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Configuration for Learning Curve plot\n",
    "CV_FOLDS_LC = 5 # Number of folds for learning curve calculation (often less than training CV for speed)\n",
    "\n",
    "# --- Load Data and Model --- (Assumes lr_feature_engineering.py and lr_train_evaluate.py were run)\n",
    "if not os.path.exists(INPUT_FEATURES_CSV) or not os.path.exists(INPUT_TARGET_CSV) or not os.path.exists(INPUT_MODEL_PATH):\n",
    "    print(f\"Error: Required input files not found.\")\n",
    "    print(f\"Please ensure '{INPUT_FEATURES_CSV}', '{INPUT_TARGET_CSV}', and '{INPUT_MODEL_PATH}' exist.\")\n",
    "else:\n",
    "    X = pd.read_csv(INPUT_FEATURES_CSV)\n",
    "    y = pd.read_csv(INPUT_TARGET_CSV).squeeze() # Use squeeze() to get a Series\n",
    "    best_model = joblib.load(INPUT_MODEL_PATH)\n",
    "\n",
    "    print(f\"Loaded final features (X) shape: {X.shape}\")\n",
    "    print(f\"Loaded target (y) shape: {y.shape}\")\n",
    "    print(\"Loaded trained Logistic Regression model.\")\n",
    "\n",
    "    # --- Reproduce Train/Test Split and Resampling --- (Same as lr_train_evaluate.py)\n",
    "    # The original data distribution needs to be balanced and split to evaluate the model correctly.\n",
    "    oversampler = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "    print(f\"\\nResampled data shape: {X_resampled.shape}\")\n",
    "    print(f\"Resampled target distribution:\\\\n{y_resampled.value_counts()}\")\n",
    "\n",
    "    # Split data into train and test sets. Stratified split is important for imbalanced data.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resampled, y_resampled,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_resampled # Use stratify to maintain class distribution\n",
    "    )\n",
    "    print(f\"\\nReproduced Train data shape: {X_train.shape}\")\n",
    "    print(f\"Reproduced Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49504e74",
   "metadata": {},
   "source": [
    "## 5.9 Results\n",
    "This section presents the primary evaluation metrics for the optimal Logistic Regression model on the test set, as discussed in Section 5.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"--- Test Set Evaluation (Section 5.9) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
